from flask import Flask, request, jsonify
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from difflib import get_close_matches
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB

# ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ§Ø±Ø¯ NLTK
nltk.download('punkt')
nltk.download('stopwords')

app = Flask(__name__)

# Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ ÙˆØ§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡Ø§
diseases_data = {
    "Diabetes": ["Frequent urination", "Excessive thirst", "Weight loss", "Fatigue", "Blurred vision", 
                 "Slow healing cuts or sores", "Frequent infections", "Tingling or numbness in hands/feet", 
                 "Increased hunger", "Dry mouth", "Itchy skin", "Darkened skin patches"],
    
    "Heart Disease": ["Chest pain", "Shortness of breath", "Arm/jaw pain", "Irregular heartbeat", "Swelling in legs", 
                      "Dizziness or lightheadedness", "Nausea or indigestion", "Cold sweats", "Fatigue during normal activities", 
                      "Persistent cough or wheezing", "Rapid weight gain"],
    
    "Cancer": ["Unexplained weight loss", "Persistent fatigue", "Lumps", "Skin changes", "Persistent cough", 
               "Changes in bowel or bladder habits", "Unusual bleeding or discharge", "Difficulty swallowing", 
               "Persistent indigestion or discomfort after eating", "Unexplained muscle or joint pain", 
               "Persistent fevers or night sweats", "Changes in moles or skin pigmentation", "Hoarseness that does not go away"]
}

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© ÙˆØ§Ø­Ø¯Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨
symptoms_list = []
disease_labels = []

for disease, symptoms in diseases_data.items():
    symptoms_list.extend(symptoms)
    disease_labels.extend([disease] * len(symptoms))

# ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… NLTK
def preprocess_text(text):
    words = word_tokenize(text.lower())  # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø£Ø­Ø±Ù ØµØºÙŠØ±Ø©
    return " ".join(word for word in words if word.isalnum() and word not in stopwords.words("english"))

# Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù‚Ø±Ø¨ Ø¹Ø±Ø¶ Ù…ØªØ·Ø§Ø¨Ù‚
def get_closest_symptom(user_input):
    matches = get_close_matches(user_input, symptoms_list, n=1, cutoff=0.6)
    return matches[0] if matches else None

# ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (ML)
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(symptoms_list)
model = MultinomialNB()
model.fit(X, disease_labels)

# Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù…Ø±Ø¶ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ù…Ø¯Ø®Ù„Ø©
def predict_disease(user_symptoms):
    symptom_vector = vectorizer.transform([" ".join(user_symptoms)])
    return model.predict(symptom_vector)[0]

# ğŸ”¹ Ø¥Ù†Ø´Ø§Ø¡ API ÙÙŠ Flask
@app.route('/predict', methods=['POST'])
def predict():
    data = request.json  # Ø§Ø³ØªÙ„Ø§Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„ÙØ±ÙˆÙ†Øª
    user_symptoms = [symptom.strip() for symptom in data.get("symptoms", [])]  # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ù…Ø¯Ø®Ù„Ø©
    matched_symptoms = []
    for symptom in user_symptoms:
        cleaned_symptom = preprocess_text(symptom)
        closest_match = get_closest_symptom(cleaned_symptom)
        if closest_match:
            matched_symptoms.append(closest_match)

    if matched_symptoms:
        predicted_disease = predict_disease(matched_symptoms)
        return jsonify({
            "matched_symptoms": matched_symptoms,
            "predicted_disease": predicted_disease
        })
    else:
        return jsonify({"error": "No matching symptoms found"}), 400

if __name__ == '__main__':
    app.run(debug=True)
